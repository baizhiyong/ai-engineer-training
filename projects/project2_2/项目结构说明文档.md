# 医疗QA模型项目结构说明文档

## 项目概述

本项目实现了基于LoRA微调的医疗领域问答模型，包含数据准备、模型训练、权重合并、模型评估和API部署的完整流程。

## 项目结构

```
project2_2/
├── data/                           # 数据目录
│   └── medical_qa_data.jsonl      # 医疗QA训练数据
├── qwen-medical-qa-lora/          # LoRA适配器输出目录（训练后生成）
│   ├── adapter_config.json        # LoRA配置文件
│   ├── adapter_model.safetensors  # LoRA权重文件
│   └── ...
├── qwen-medical-qa-merged/        # 合并后模型目录（合并后生成）
│   ├── config.json               # 模型配置
│   ├── model.safetensors         # 模型权重
│   ├── tokenizer.json            # 分词器
│   └── merge_info.json           # 合并信息
├── logs/                          # 日志目录（运行时生成）
├── train_medical_qa.py           # 医疗QA模型训练脚本
├── merge_lora_weights.py         # LoRA权重合并脚本
├── evaluate_model.py             # 模型评估脚本
├── api_server.py                 # FastAPI服务器
├── requirements.txt              # 项目依赖
├── FAQ.md                        # 技术FAQ文档
├── 项目描述.txt                   # 项目需求描述
└── 项目结构说明文档.md            # 本文档
```

## 文件功能说明

### 核心脚本文件

#### 1. train_medical_qa.py
**功能**：医疗QA模型训练脚本
**主要特性**：
- 基于Qwen2.5-7B-Instruct模型进行LoRA微调
- 支持4-bit量化训练，节省显存
- 使用医疗对话格式进行训练
- 自动划分训练集和验证集

**使用方法**：
```bash
python train_medical_qa.py
```

**关键参数**：
- `MODEL_NAME`: 基础模型名称
- `OUTPUT_DIR`: 输出目录
- `MAX_LENGTH`: 最大序列长度
- `BATCH_SIZE`: 批次大小
- `EPOCHS`: 训练轮数
- `LEARNING_RATE`: 学习率

#### 2. merge_lora_weights.py
**功能**：将LoRA权重合并到基础模型中
**主要特性**：
- 支持命令行参数配置
- 自动验证合并后的模型
- 提供模型大小对比功能
- 保存合并信息记录

**使用方法**：
```bash
python merge_lora_weights.py \
    --base_model Qwen/Qwen2.5-7B-Instruct \
    --lora_model ./qwen-medical-qa-lora \
    --output ./qwen-medical-qa-merged
```

**参数说明**：
- `--base_model`: 基础模型路径
- `--lora_model`: LoRA适配器路径
- `--output`: 合并后模型保存路径
- `--device`: 设备类型（auto/cpu/cuda）
- `--compare`: 是否比较模型大小

#### 3. evaluate_model.py
**功能**：评估模型在医疗QA任务上的性能
**主要特性**：
- 多维度评估指标（ROUGE、BERTScore）
- 支持采样评估
- 生成详细的评估报告
- 保存评估示例

**使用方法**：
```bash
python evaluate_model.py \
    --model_path ./qwen-medical-qa-merged \
    --data_path data/medical_qa_data.jsonl \
    --output_path evaluation_results.json
```

**评估指标**：
- ROUGE-1/2/L: 文本重叠度
- BERTScore: 语义相似度
- 答案长度统计
- 生成示例展示

#### 4. api_server.py
**功能**：FastAPI服务器，提供问答API接口
**主要特性**：
- RESTful API设计
- 支持参数化生成
- 健康检查接口
- 模型信息查询
- 异常处理和日志记录

**使用方法**：
```bash
python api_server.py --model_path ./qwen-medical-qa-merged --port 8000
```

**API接口**：
- `GET /`: 根路径，显示API信息
- `GET /health`: 健康检查
- `POST /ask`: 问答接口
- `GET /model_info`: 模型信息
- `POST /reload_model`: 重新加载模型

### 数据文件

#### data/medical_qa_data.jsonl
**格式**：每行一个JSON对象
```json
{
  "question": "什么是高血压？",
  "answer": "高血压是指血压持续升高的慢性疾病..."
}
```

**内容覆盖**：
- 心血管疾病
- 内分泌疾病
- 呼吸系统疾病
- 消化系统疾病
- 神经系统疾病
- 预防保健知识

### 配置文件

#### requirements.txt
项目依赖包列表，包含：
- 深度学习框架：torch, transformers
- 微调工具：peft, accelerate
- 量化工具：bitsandbytes
- API框架：fastapi, uvicorn
- 评估工具：rouge-score, bert-score
- 数据处理：datasets, scikit-learn

## 使用流程

### 1. 环境准备
```bash
# 创建虚拟环境
python -m venv venv
source venv/bin/activate  # Linux/Mac
# 或
venv\Scripts\activate     # Windows

# 安装依赖
pip install -r requirements.txt
```

### 2. 数据准备
数据已经准备好在 `data/medical_qa_data.jsonl`，包含30个医疗QA对。
如需添加更多数据，请按照相同格式添加到文件中。

### 3. 模型训练
```bash
# 开始训练（需要GPU支持）
python train_medical_qa.py

# 训练完成后，LoRA适配器将保存在 ./qwen-medical-qa-lora/
```

### 4. 权重合并
```bash
# 合并LoRA权重到基础模型
python merge_lora_weights.py \
    --base_model Qwen/Qwen2.5-7B-Instruct \
    --lora_model ./qwen-medical-qa-lora \
    --output ./qwen-medical-qa-merged \
    --compare
```

### 5. 模型评估
```bash
# 评估合并后的模型
python evaluate_model.py \
    --model_path ./qwen-medical-qa-merged \
    --data_path data/medical_qa_data.jsonl \
    --output_path evaluation_results.json \
    --sample_size 10
```

### 6. API部署
```bash
# 启动API服务
python api_server.py \
    --model_path ./qwen-medical-qa-merged \
    --host 0.0.0.0 \
    --port 8000

# 访问API文档：http://localhost:8000/docs
```

### 7. API测试
```bash
# 测试问答接口
curl -X POST "http://localhost:8000/ask" \
     -H "Content-Type: application/json" \
     -d '{
       "question": "什么是糖尿病？",
       "max_length": 256,
       "temperature": 0.7
     }'
```

## 性能优化建议

### 训练优化
1. **显存优化**：
   - 使用4-bit量化：`load_in_4bit=True`
   - 启用梯度检查点：`gradient_checkpointing=True`
   - 调整批次大小：根据显存大小调整`BATCH_SIZE`

2. **训练效率**：
   - 使用混合精度：`fp16=True`
   - 梯度累积：`gradient_accumulation_steps=4`
   - 预热步数：`warmup_steps=10`

### 推理优化
1. **模型量化**：使用INT8或INT4量化减少内存占用
2. **批量推理**：支持批量处理提高吞吐量
3. **KV缓存**：启用KV缓存加速生成
4. **异步处理**：使用异步API提高并发性能

### 部署优化
1. **容器化部署**：使用Docker进行容器化部署
2. **负载均衡**：使用Nginx等进行负载均衡
3. **监控告警**：添加性能监控和告警机制
4. **缓存策略**：实现智能缓存减少重复计算

## 扩展功能

### 1. 多模态支持
- 添加图像输入支持
- 支持医学影像问答
- 集成OCR文本识别

### 2. 知识图谱集成
- 构建医学知识图谱
- 实现知识增强生成
- 支持推理链展示

### 3. 多语言支持
- 支持英文医疗问答
- 添加医学术语翻译
- 跨语言知识迁移

### 4. 安全增强
- 添加内容安全过滤
- 实现敏感信息检测
- 增加医疗免责声明

## 故障排除

### 常见问题

1. **CUDA内存不足**
   - 减少批次大小
   - 启用CPU offload
   - 使用更高的量化级别

2. **模型加载失败**
   - 检查模型路径是否正确
   - 确认网络连接正常
   - 验证磁盘空间充足

3. **API响应慢**
   - 检查模型是否在GPU上
   - 优化生成参数
   - 考虑模型量化

4. **评估指标异常**
   - 检查数据格式是否正确
   - 确认模型输出格式
   - 验证评估脚本参数

### 日志查看
```bash
# 查看训练日志
tail -f ./qwen-medical-qa-lora/logs/events.out.tfevents.*

# 查看API日志
tail -f api_server.log
```

## 贡献指南

1. **代码规范**：遵循PEP 8编码规范
2. **文档更新**：及时更新相关文档
3. **测试覆盖**：添加必要的单元测试
4. **性能测试**：进行性能基准测试

## 许可证

本项目采用MIT许可证，详见LICENSE文件。

## 联系方式

如有问题或建议，请通过以下方式联系：
- 项目Issues：提交GitHub Issues
- 邮件联系：[项目维护者邮箱]
- 技术讨论：[技术交流群]