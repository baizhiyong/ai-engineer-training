{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b146087",
   "metadata": {},
   "source": [
    "## 1. 权重量化（Quantization）\n",
    "将 FP32 转为 INT8/INT4 等低位精度。\n",
    "\n",
    "```python\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "model_id = \"EleutherAI/gpt-neo-125M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, load_in_8bit=True, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "```\n",
    "\n",
    "## 2. 权重剪枝（Pruning）\n",
    "删除不重要的权重连接以减小模型规模。可用 torch.nn.utils.prune 实现。\n",
    "```python\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "prune.random_unstructured(model.transformer.h[0].attn.c_proj, name=\"weight\", amount=0.3)\n",
    "```\n",
    "\n",
    "## 3. 知识蒸馏（Knowledge Distillation）\n",
    "训练一个小模型 mimick 大模型的行为。\n",
    "```python\n",
    "# 简化伪代码\n",
    "teacher_logits = teacher(input_ids).logits\n",
    "student_logits = student(input_ids).logits\n",
    "loss = nn.KLDivLoss()(F.log_softmax(student_logits), F.softmax(teacher_logits))\n",
    "```\n",
    "\n",
    "\n",
    "参考来源： https://cloud.tencent.com/developer/article/2546431"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
